{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44661,"status":"ok","timestamp":1677753023267,"user":{"displayName":"Yuval Bayer","userId":"06448299427644141054"},"user_tz":-120},"id":"wKilBa9_2cEm","outputId":"ae2ac3da-c077-46f9-84e1-cc0dddfaa4d4"},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\yuval\\miniconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","import torch\n","import pandas as pd\n","import torch.nn.functional as F\n","\n","# Colab - Pytorch Geometric installation according to Pytorch documentation\n","'''\n","os.environ['TORCH'] = torch.__version__\n","print(torch.__version__)\n","!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n","!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n","'''\n","\n","from torch_geometric.data import Dataset, Data\n","from torch_geometric.loader import DataLoader\n","from torch.nn import Linear\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","\n","from IPython.display import Javascript"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25284,"status":"ok","timestamp":1677753120375,"user":{"displayName":"Yuval Bayer","userId":"06448299427644141054"},"user_tz":-120},"id":"s4FEnh3l2cEr","outputId":"03d3585c-a083-4535-ab63-16e37e0702c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["C:\\Users\\yuval\\Projects\\MolecularGraphs\n"]},{"data":{"text/plain":["\"\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n%cd drive/MyDrive/MolecularGraphs/\\n\""]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# Local machine\n","%cd C:\\Users\\yuval\\Projects\\MolecularGraphs\n","\n","# Colab\n","'''\n","from google.colab import drive\n","drive.mount('/content/drive')\n","%cd drive/MyDrive/MolecularGraphs/\n","'''"]},{"cell_type":"markdown","metadata":{"id":"96yQBi8V2cEr"},"source":["## Preparing the dataset:"]},{"cell_type":"markdown","metadata":{"id":"eM3Cl8cj4Teb"},"source":["### Defining custom Dataset:"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ha2Nnp9x2cEt"},"source":["The `Dataset` class is designed to sample batches from storage without uploading all data into the RAM.\n","To create our own custom operation we need to create a class that inherent from `Dataset` class.\n","\n","In the `init` method, the arguments that are pass to `Dataset` are:\n","* `root` (str, optional) - The root directory where the data should be saved.\n","This directory is going to have `raw` directory and `processed` directory.\n","The `raw` directory is where you have all files of the data, a file per instance.\n","The `processed` directory is where the class is going to saved all processed files.\n","The processing of files in our case is the convertion of the file into a `Data` object (including node features, edge index, label/s, and optional of edges features).\n","* `transform` (callable, optional) - not used - a function/transform that takes in an `Data` object and returns a transformed version. The `Data` object will be **transformed before every access**.\n","* `pre_transform` (callable, optional) - not used â€“ a function/transform that takes in an `Data` object and returns a transformed version. The `Data` object will be **transformed before being saved to disk**. (default: None)\n","* `pre_filter` (callable, optional) - not used - a function that takes in an `Data` object and returns a boolean value, indicating whether the `Data` object should be included in the final dataset. \n","* `log` (bool, optional) - whether to print any console output while downloading and processing the dataset.\n","\n","Following the `init` method, we have two method decorated as property.\n","The decorator define the method as a \"getter\", i.e., getting an attribute of the class.\n","That means we can treat such method as an attribute and call it without parentheses.\n","Those two properties return all files names inside the previously mentioned directories - `raw` and `processed`.\n","Those two properties are designed for the class to check if the raw/processes files exsit before performing the dolwnloading/processing.\n","\n","The `process` method is called with calling the `Dataset`'s `init` method (I think).\n","In this method you iterate over all of the raw files and turn them into `Data` object of graph, including the `pre_transform` and `pre_filter` functions calls.\n","\n","The `len` and `get` are self-explanable.\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":26,"metadata":{"id":"p8aXFs3d2cEv"},"outputs":[],"source":["class MyDataset(Dataset):\n","    def __init__(self, root, transform=None, pre_transform=None, pre_filter=None):\n","        super().__init__(root, transform, pre_transform, pre_filter)\n","\n","    @property\n","    def raw_file_names(self):\n","        return os.listdir(self.raw_dir)\n","\n","    @property\n","    def processed_file_names(self):\n","        data_file_names = [os.path.splitext(file_name)[0]+ '.pt' for file_name in self.raw_file_names]\n","        return data_file_names + ['pre_filter.pt', 'pre_transform.pt']\n","\n","\n","    def process(self):\n","        idx = 0\n","        for raw_path in self.raw_paths:\n","\n","            # Load the two arrays and scaler from the saved file using read_pickle()\n","            with open(raw_path, 'rb') as f:\n","                x, edge_index, y = pd.read_pickle(f)\n","            \n","            data_i = Data(x=torch.tensor(x),\n","                          edge_index=torch.tensor(edge_index),\n","                          y=torch.tensor([int(y)])) # You want the y as 1D int and not a scaler\n","\n","            if self.pre_filter is not None and not self.pre_filter(data_i):\n","                continue\n","\n","            if self.pre_transform is not None:\n","                data_i = self.pre_transform(data_i)\n","\n","            torch.save(data_i, os.path.join(self.processed_dir, f'data_{idx}.pt'))\n","            idx += 1\n","\n","    def len(self):\n","        return len(self.processed_file_names) - 2 # minus the pre_filter and pre_transform\n","\n","    def get(self, idx):\n","        data_i = torch.load(os.path.join(self.processed_dir, f'data_{idx}.pt'))\n","        return data_i"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"elapsed":264700,"status":"error","timestamp":1677753525788,"user":{"displayName":"Yuval Bayer","userId":"06448299427644141054"},"user_tz":-120},"id":"ycEHMDvE4l0s","outputId":"e7de99a1-0869-41c6-8a72-147f1cc26274"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing...\n","Done!\n"]}],"source":["# Local machine\n","dataset = MyDataset('Zinc\\GraphData')\n","\n","# Colab\n","#dataset = MyDataset('Zinc/GraphData')"]},{"cell_type":"markdown","metadata":{"id":"49rlrZdI4YBn"},"source":["### Examination:"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"dTGsF5GS2cEw","outputId":"d0fb457a-b896-4c38-da88-1ea8b1b7259d"},"outputs":[{"data":{"text/plain":["Data(x=[19, 11], edge_index=[2, 40], y=0)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["data = dataset.get(10)\n","data"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"M6BXVPJM2cEw","outputId":"d0a5c249-9e89-4a92-a1fb-8ca7f667871f"},"outputs":[{"data":{"text/plain":["tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=torch.float64)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["data.x"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"dm8LEbPX2cEx","outputId":"faff1f32-35de-4434-ac38-e9728fec38e6"},"outputs":[{"data":{"text/plain":["tensor([[ 0,  1,  1,  1,  2,  3,  3,  4,  4,  5,  5,  5,  6,  6,  6,  7,  7,  8,\n","          8,  9,  9,  9, 10, 11, 11, 12, 12, 13, 13, 13, 14, 14, 15, 15, 16, 16,\n","         17, 17, 18, 18],\n","        [ 1,  0,  2,  3,  1,  1,  4,  3,  5,  4,  6, 13,  5,  7, 12,  6,  8,  7,\n","          9,  8, 10, 11,  9,  9, 12,  6, 11,  5, 14, 18, 13, 15, 14, 16, 15, 17,\n","         16, 18, 13, 17]])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["data.edge_index"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["tensor(0)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["data.y"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Y1dIIKI12cEy"},"outputs":[],"source":["loader = DataLoader(dataset, batch_size=32, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"0gJ-RKAY2cEy"},"source":["To split the data into training, validation and test sets, we use the `index_select` method which creates a subset of the dataset from specified indices idx."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d6wg07Oe2cEy"},"outputs":[],"source":["N = dataset.len()\n","idx = torch.randperm(N) # Random permutation of integers from 0 to N - 1\n","idx_train, idx_val, idx_test = idx[:int(0.8 * N)], idx[int(0.8 * N): int(0.9 * N)], idx[int(0.9 * N):]\n","\n","train_dataset = dataset.index_select(idx_train)\n","val_dataset = dataset.index_select(idx_val)\n","test_dataset = dataset.index_select(idx_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ffXhq27g2cEy","outputId":"9da2b8fc-4e7e-4504-a4eb-0ee8d125215a"},"outputs":[],"source":["dataset.len()"]},{"cell_type":"markdown","metadata":{"id":"nQTGRXOS2cEz"},"source":["Now we define the `Dataloader`.\n","Note for thet `shuffle` parameter, if set to True, the data will be reshuffled at every epoch.\n","We do not want such thing for the validation and test sets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZoUHxzA2cEz"},"outputs":[],"source":["train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VRsQl6O02cEz","outputId":"4260f5d5-8857-4e24-bb9c-03fff9b9d36c"},"outputs":[],"source":["for step, data in enumerate(train_loader):\n","    print(f'Step {step + 1}:')\n","    print('=======')\n","    print(f'Number of graphs in the current batch: {data.num_graphs}')\n","    print(data)\n","    print()"]},{"cell_type":"markdown","metadata":{"id":"aun3SS5p2cEz"},"source":["## Training:"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":339},"executionInfo":{"elapsed":10,"status":"error","timestamp":1677753184769,"user":{"displayName":"Yuval Bayer","userId":"06448299427644141054"},"user_tz":-120},"id":"9_1jHMv82cEz","outputId":"1fce9f3d-ac5e-4d9a-c139-3421b41819b3"},"outputs":[{"name":"stdout","output_type":"stream","text":["GCN(\n","  (conv1): GCNConv(11, 64)\n","  (conv2): GCNConv(64, 64)\n","  (conv3): GCNConv(64, 64)\n","  (lin): Linear(in_features=64, out_features=2, bias=True)\n",")\n"]}],"source":["class GCN(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super(GCN, self).__init__()\n","        torch.manual_seed(12345)\n","        self.conv1 = GCNConv(dataset.num_node_features, hidden_channels)\n","        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n","        self.conv3 = GCNConv(hidden_channels, hidden_channels)\n","        self.lin = Linear(hidden_channels, dataset.num_classes)\n","\n","    def forward(self, x, edge_index, batch):\n","        # 1. Obtain node embeddings \n","        x = self.conv1(x, edge_index)\n","        x = x.relu()\n","        x = self.conv2(x, edge_index)\n","        x = x.relu()\n","        x = self.conv3(x, edge_index)\n","\n","        # 2. Readout layer\n","        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n","\n","        # 3. Apply a final classifier\n","        x = F.dropout(x, p=0.5, training=self.training)\n","        x = self.lin(x)\n","        \n","        return x\n","\n","model = GCN(hidden_channels=64)\n","print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cCsgC2Jy2cE0"},"outputs":[],"source":["def train(criterion, optimizer, train_loader):\n","    model.train()\n","\n","    for data in train_loader:  # Iterate in batches over the training dataset.\n","         out = model(data.x, data.edge_index, data.batch)  # Perform a single forward pass.\n","         loss = criterion(out, data.y)  # Compute the loss.\n","         loss.backward()  # Derive gradients.\n","         optimizer.step()  # Update parameters based on gradients.\n","         optimizer.zero_grad()  # Clear gradients.\n","         loss_sum += loss\n","\n","def eval(criterion, loader):\n","    model.eval()\n","\n","    loss_sum = 0\n","    correct = 0\n","\n","    for data in loader:  # Iterate in batches over the training/test dataset.\n","        out = model(data.x, data.edge_index, data.batch)\n","         \n","        # Compute the loss sum\n","        loss_sum += criterion(out, data.y)  \n","        \n","        # Compute accuracy\n","        pred = out.argmax(dim=1)  # Use the class with highest probability.\n","        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n","\n","    acc = correct / len(loader.dataset)  # Derive ratio of correct predictions.\n","    loss_mean = loss_sum / len(loader.dataset)\n","    return acc, loss_mean"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYZR3UMb2cE0"},"outputs":[],"source":["display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'''))\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","model = GCN(hidden_channels=64).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","train_dataset = dataset.index_select(idx_train).to(device)\n","val_dataset = dataset.index_select(idx_val).to(device)\n","test_dataset = dataset.index_select(idx_test).to(device)\n","\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","for epoch in range(1, 171):\n","    train(criterion, optimizer, train_loader)\n","    train_acc, train_loss = eval(criterion, train_loader)\n","    val_acc, val_loss = eval(criterion, val_loader)\n","    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["49rlrZdI4YBn"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"pytorch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"789b5c918ca4ed31f62df3a061c2d98786479cc50a729b77b7a1d38d9deddd09"}}},"nbformat":4,"nbformat_minor":0}
